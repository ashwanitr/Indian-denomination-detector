{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import Functions\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Conv2D,concatenate, BatchNormalization, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.nasnet import NASNetMobile\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "import keras.models as model\n",
    "from PIL import ImageFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1592 images belonging to 7 classes.\n",
      "Found 381 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set this to the current working directory\n",
    "os.chdir(\"/home/ashwani/Deep_learning_Scripts\")\n",
    "\n",
    "if not os.path.isdir(\"Weights\"):\n",
    "    os.mkdir(\"Weights\")\n",
    "\n",
    "# Set the inital parameters according the needs\n",
    "# Generally Image size of 224, 224 is goood enough,\n",
    "# We can set up the other parameters according to the training needs\n",
    "batch_size = 3\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "epochs = 10\n",
    "learn_rate = 1e-5\n",
    "# Number of classes in the problem statement\n",
    "nclasses =  7\n",
    "\n",
    "# Setting up[ the numbers of frozen layers\n",
    "# frezzed layers wont be trained and hence we can make use of pre learned model.\n",
    "\n",
    "layers_frozen=0\n",
    "# Path for saving the results\n",
    "\n",
    "model_path = './'\n",
    "\n",
    "# setting the train data path\n",
    "train_data_dir =\"/home/ashwani/Deep_learning_Scripts/Train\"\n",
    "# validation data path\n",
    "validation_data_dir = \"/home/ashwani/Deep_learning_Scripts/Validate\"\n",
    "\n",
    "# Setting up name for logs\n",
    "Name = \"InceptionResnetV2\".format(int(time.time())) \n",
    "\n",
    "\n",
    "\n",
    "#Image-PreProcessing\n",
    "# These steps creates train and validation_datagen for tarining and validation data\n",
    "# Parameters involves the parameters for pre processing the images\n",
    "# In other words augmenting images for better results\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,width_shift_range=0.3,\n",
    "                                   height_shift_range=0.3,rotation_range=30,shear_range=0.5,zoom_range=.7,\n",
    "                                   channel_shift_range=0.3,cval=0.5,vertical_flip=True,fill_mode='nearest')\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(\n",
    "    img_height, img_width), batch_size=batch_size, class_mode='categorical')\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir, target_size=(\n",
    "    img_height, img_width), batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "# Setting up the train steps and val steps on the basis of length of data gens\n",
    "# These params will be used while model training\n",
    "\n",
    "train_steps = train_generator.__len__()\n",
    "val_steps = validation_generator.__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecting the pretrained model for transfer learning\n",
    "# Generally Nasnet is slowest and most accurate\n",
    "#  We can select the architecture depending upon the processing power.\n",
    "# For general purposes Resnet50 will suffice.\n",
    "\n",
    "architecture=3\n",
    "\n",
    "if architecture==1:\n",
    "    base_model = InceptionResNetV2(input_shape=(img_height, img_width, 3), weights='imagenet', include_top=False)\n",
    "    architecture_name=\"InceptionResNetV2\"\n",
    "elif architecture==2:\n",
    "    base_model = DenseNet121(input_shape=(img_height, img_width, 3), weights='imagenet', include_top=False)\n",
    "    architecture_name=\"DenseNet121\"\n",
    "elif architecture==3:\n",
    "    base_model = ResNet50(input_shape=(img_height, img_width, 3), weights='imagenet', include_top=False)\n",
    "    architecture_name=\"ResNet50\"\n",
    "elif architecture==4:\n",
    "    base_model = NASNetMobile(input_shape=(img_height, img_width, 3), weights='imagenet', include_top=False)\n",
    "    architecture_name=\"NASNetMobile\"\n",
    "elif architecture==5:\n",
    "    base_model = MobileNet(input_shape=(img_height, img_width, 3), weights='imagenet', include_top=False)\n",
    "    architecture_name=\"MobileNet\"\n",
    "elif architecture==6:\n",
    "    base_model = InceptionV3(input_shape=(img_height, img_width, 3), weights='imagenet', include_top=False)\n",
    "    architecture_name=\"InceptionV3\"\n",
    "else:\n",
    "    print (\"Wrong Architecture Input\")\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(nclasses, activation='softmax')(x)\n",
    "pmodel = Model(base_model.input, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> done building model <=\n"
     ]
    }
   ],
   "source": [
    "# Setting up the model\n",
    "\n",
    "model = pmodel\n",
    "for layer in model.layers[:-layers_frozen]:\n",
    "    layer.trainable = False\n",
    "\n",
    "nadam = Nadam(lr=learn_rate)\n",
    "\n",
    "model.compile(optimizer=nadam, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "print('=> done building model <=')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> created callback objects <=\n",
      "=> initializing training loop <=\n",
      "WARNING:tensorflow:From <ipython-input-5-1fc861b7b63a>:27: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 531 steps, validate for 127 steps\n",
      "Epoch 1/10\n",
      "530/531 [============================>.] - ETA: 1s - loss: 1.7063 - accuracy: 0.3317\n",
      "Epoch 00001: saving model to /home/ashwani/Deep_learning_Scripts/Weights/top_model_weights_Frozen_Layers.h5\n",
      "531/531 [==============================] - 711s 1s/step - loss: 1.7052 - accuracy: 0.3323 - val_loss: 1.8543 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "530/531 [============================>.] - ETA: 1s - loss: 1.2985 - accuracy: 0.5198\n",
      "Epoch 00002: saving model to /home/ashwani/Deep_learning_Scripts/Weights/top_model_weights_Frozen_Layers.h5\n",
      "531/531 [==============================] - 698s 1s/step - loss: 1.2977 - accuracy: 0.5207 - val_loss: 0.6862 - val_accuracy: 0.7822\n",
      "Epoch 3/10\n",
      "530/531 [============================>.] - ETA: 1s - loss: 1.0277 - accuracy: 0.6583\n",
      "Epoch 00003: saving model to /home/ashwani/Deep_learning_Scripts/Weights/top_model_weights_Frozen_Layers.h5\n",
      "531/531 [==============================] - 688s 1s/step - loss: 1.0271 - accuracy: 0.6583 - val_loss: 0.5538 - val_accuracy: 0.8110\n",
      "Epoch 4/10\n",
      "530/531 [============================>.] - ETA: 1s - loss: 0.9346 - accuracy: 0.6690\n",
      "Epoch 00004: saving model to /home/ashwani/Deep_learning_Scripts/Weights/top_model_weights_Frozen_Layers.h5\n",
      "531/531 [==============================] - 692s 1s/step - loss: 0.9343 - accuracy: 0.6690 - val_loss: 0.4350 - val_accuracy: 0.8609\n",
      "Epoch 5/10\n",
      "530/531 [============================>.] - ETA: 1s - loss: 0.8318 - accuracy: 0.7281\n",
      "Epoch 00005: saving model to /home/ashwani/Deep_learning_Scripts/Weights/top_model_weights_Frozen_Layers.h5\n",
      "531/531 [==============================] - 691s 1s/step - loss: 0.8319 - accuracy: 0.7274 - val_loss: 0.3990 - val_accuracy: 0.8924\n",
      "Epoch 6/10\n",
      "530/531 [============================>.] - ETA: 1s - loss: 0.7660 - accuracy: 0.7426\n",
      "Epoch 00006: saving model to /home/ashwani/Deep_learning_Scripts/Weights/top_model_weights_Frozen_Layers.h5\n",
      "531/531 [==============================] - 694s 1s/step - loss: 0.7657 - accuracy: 0.7425 - val_loss: 0.3472 - val_accuracy: 0.8845\n",
      "Epoch 7/10\n",
      "530/531 [============================>.] - ETA: 1s - loss: 0.7414 - accuracy: 0.7546\n",
      "Epoch 00007: saving model to /home/ashwani/Deep_learning_Scripts/Weights/top_model_weights_Frozen_Layers.h5\n",
      "531/531 [==============================] - 696s 1s/step - loss: 0.7414 - accuracy: 0.7544 - val_loss: 0.3153 - val_accuracy: 0.8924\n",
      "Epoch 8/10\n",
      "530/531 [============================>.] - ETA: 1s - loss: 0.6760 - accuracy: 0.7841\n",
      "Epoch 00008: saving model to /home/ashwani/Deep_learning_Scripts/Weights/top_model_weights_Frozen_Layers.h5\n",
      "531/531 [==============================] - 696s 1s/step - loss: 0.6775 - accuracy: 0.7833 - val_loss: 0.3095 - val_accuracy: 0.9003\n",
      "Epoch 9/10\n",
      "530/531 [============================>.] - ETA: 1s - loss: 0.6479 - accuracy: 0.7948\n",
      "Epoch 00009: saving model to /home/ashwani/Deep_learning_Scripts/Weights/top_model_weights_Frozen_Layers.h5\n",
      "531/531 [==============================] - 696s 1s/step - loss: 0.6486 - accuracy: 0.7946 - val_loss: 0.2845 - val_accuracy: 0.9081\n",
      "Epoch 10/10\n",
      "530/531 [============================>.] - ETA: 1s - loss: 0.5938 - accuracy: 0.8143\n",
      "Epoch 00010: saving model to /home/ashwani/Deep_learning_Scripts/Weights/top_model_weights_Frozen_Layers.h5\n",
      "531/531 [==============================] - 702s 1s/step - loss: 0.5929 - accuracy: 0.8147 - val_loss: 0.2578 - val_accuracy: 0.9186\n"
     ]
    }
   ],
   "source": [
    "# Storing logs of learning using Tensorboard\n",
    "\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir='./logs'.format(Name), histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "# File path for storing model weights\n",
    "\n",
    "filepath=os.path.join(\n",
    "                                os.path.abspath(model_path), 'Weights/top_model_weights_'+'Frozen_Layers.h5')\n",
    "\n",
    "\n",
    "\n",
    "# Setting up the checkpoints for model\n",
    "# checkpoints helps in storing the best trained model only\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print('=> created callback objects <=')\n",
    "print('=> initializing training loop <=')\n",
    "\n",
    "# Running the model\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=train_steps, epochs=epochs,\n",
    "                              validation_data=validation_generator, validation_steps=val_steps,\n",
    "                              workers=2, \n",
    "                              use_multiprocessing=False, \n",
    "                              max_queue_size=500, \n",
    "                              callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading best weights <=\n",
      "=> saving final model <=\n"
     ]
    }
   ],
   "source": [
    "filepath=os.path.join(\n",
    "                                os.path.abspath(model_path), 'Weights/top_model_weights_'+'Frozen_Layers.h5')\n",
    "\n",
    "print('=> loading best weights <=')\n",
    "model.load_weights(filepath)\n",
    "print('=> saving final model <=')\n",
    "Final_Weights='Weights/model_'+architecture_name+\"_\"+str(layers_frozen)+'Frozen_Layers.h5'\n",
    "pmodel.save(os.path.join(os.path.abspath(model_path), Final_Weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These steps are only for checking predictions and only needed \n",
    "# to run if you need to check predictions on your data\n",
    "\n",
    "\n",
    "# Loading the model with best weights\n",
    "\n",
    "new_model=tf.keras.models.load_model(filepath)\n",
    "#new_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions\n",
    "\n",
    "\n",
    "predictions=[]\n",
    "\n",
    "# Set up this to the validation images path\n",
    "img_path= \"/home/ashwani/Deep_learning_Scripts/Validate/\"  #Set This To The Val Directory Path\n",
    "\n",
    "# Path to csv file that will store the results\n",
    "\n",
    "CSV_Name=\"/home/ashwani/Deep_learning_Scripts/Validate.csv\"    #Set CSV Name To Be Generated\n",
    "filenames=validation_generator.filenames\n",
    "for i in filenames:\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path+i, target_size=(224, 224))\n",
    "    x = tf.keras.preprocessing.image.img_to_array(img) \n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    y=new_model.predict(x)\n",
    "    predict=str(y.argmax(axis=-1))\n",
    "    predict=predict.replace(\"[\",\"\")\n",
    "    predict=predict.replace(\"]\",\"\")\n",
    "    predict=int(predict)\n",
    "    predictions.append(predict)\n",
    "labels = (validation_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "labels[4]='None'\n",
    "predicted = [labels[k] for k in predictions]\n",
    "results=pd.DataFrame({\"Filename\":filenames,\"Predictions\":predicted})\n",
    "actual=[]\n",
    "for i in results['Filename']:\n",
    "    head, sep, tail = i.partition('/')\n",
    "    actual.append(head)\n",
    "results['Actual']=actual\n",
    "results.to_csv(CSV_Name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
